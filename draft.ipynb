{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josegfer/miniconda3/envs/wavernn/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import torch\n",
    "import numba\n",
    "from numba import cuda, prange\n",
    "#import cupy as cp\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(DEVICE)\n",
    "\n",
    "class GG:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def torch(self, X: np.ndarray):\n",
    "        X = torch.Tensor(X).to(DEVICE)\n",
    "        n = X.shape[0]\n",
    "        F = torch.cdist(X,X)**2\n",
    "        F.fill_diagonal_(float('inf'))\n",
    "\n",
    "        adj = torch.zeros((n,n), dtype=torch.bool).to(DEVICE)\n",
    "        for i in tqdm(range(n-1)):\n",
    "            A = F[i]+F[i+1:]\n",
    "            idx_min = torch.argmin(A, axis=1)\n",
    "            a = A[torch.arange(A.shape[0]), idx_min] - F[i, i+1:]\n",
    "            adj[i, i+1:] = torch.where(a > 0, 1, 0)\n",
    "        adj = adj + adj.T\n",
    "        return adj\n",
    "    \n",
    "    def torch_batch_ii(self, X: np.ndarray, btsz: int, tol: int):\n",
    "        X = torch.Tensor(X).to(DEVICE)\n",
    "        n = X.shape[0]\n",
    "        tol = 1e-6\n",
    "        # F = torch.cdist(X,X)**2\n",
    "        # F.fill_diagonal_(float('inf'))\n",
    "\n",
    "        adj = torch.zeros((n,n), dtype=torch.bool).to(DEVICE)\n",
    "        print(len(range(0, n-1, btsz)))\n",
    "        for i in (range(0, n-1, btsz)):\n",
    "            ii = slice(i, min(i + btsz, n))\n",
    "            Fi = torch.cdist(X[ii, :], X)**2\n",
    "            Fi[Fi < tol] = float('inf')\n",
    "            for j in tqdm(range(i, n)):\n",
    "                Fj = torch.cdist(X[j:j+1, :], X)**2\n",
    "                Fj[:, j] = float('inf')\n",
    "                A = Fi + Fj\n",
    "                idx_min = torch.argmin(A, axis = 1)\n",
    "                a = A[torch.arange(A.shape[0]), idx_min] - Fj[:, ii]\n",
    "                adj[ii, j] = torch.where(a > 0, 1, 0)\n",
    "            del Fi\n",
    "        adj = adj + adj.T\n",
    "        return adj\n",
    "    \n",
    "    def torch_batch_jj(self, X: np.ndarray, btsz: int, tol: int):\n",
    "        X = torch.Tensor(X).to(DEVICE)\n",
    "        n = X.shape[0]\n",
    "        # F = torch.cdist(X,X)**2\n",
    "        # F.fill_diagonal_(float('inf'))\n",
    "\n",
    "        adj = torch.zeros((n,n), dtype=torch.bool).to(DEVICE)\n",
    "        # adj = torch.tensor([], dtype = torch.int).to(DEVICE)\n",
    "        for i in tqdm(range(n-1)):\n",
    "            # A = F[i]+F[i+1:]\n",
    "            # idx_min = torch.argmin(A, axis=1)\n",
    "            # a = A[torch.arange(A.shape[0]), idx_min] - F[i, i+1:]\n",
    "            # adj[i, i+1:] = torch.where(a > 0, 1, 0)\n",
    "            Fi = torch.cdist(X[i:i+1, :], X)**2\n",
    "            Fi[:, i] = float('inf')\n",
    "            for j in (range(i+1, n, btsz)):\n",
    "                jj = slice(j, min(j + btsz, n))\n",
    "                Fjj = torch.cdist(X[jj, :], X)**2\n",
    "                Fjj[Fjj < tol] = float('inf')\n",
    "                A = Fi + Fjj\n",
    "                idx_min = torch.argmin(A, axis = 1)\n",
    "                a = A[torch.arange(A.shape[0]), idx_min] - Fjj[:, i]\n",
    "                adj[i, jj] = torch.where(a > 0, 1, 0)\n",
    "                # mask = torch.where(a > 0, True, False)\n",
    "                # idx = torch.arange(jj.start, jj.stop).to(DEVICE)[mask]\n",
    "                # idx = torch.stack((torch.full_like(idx, i), idx), dim = 1)\n",
    "                # adj = torch.cat((adj, idx))\n",
    "        adj = adj + adj.T\n",
    "        return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H = np.load('data/H_train.npy')\n",
    "X = np.load('data/H_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "# sz = 10000\n",
    "# print(sz, batch_size)\n",
    "# idx = np.random.choice(len(H), size = sz)\n",
    "# X = H[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggclass = GG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj = ggclass.torch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_batch = ggclass.torch_batch_jj(X, btsz = batch_size, tol = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label, counts = np.unique(adj.cpu() == adj_batch.cpu(), return_counts = True)\n",
    "# print(label, counts / sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [17:51<00:00, 55.97it/s]\n",
      "100%|██████████| 50000/50000 [14:53<00:00, 55.97it/s]\n",
      "100%|██████████| 40000/40000 [11:54<00:00, 55.97it/s]\n",
      "100%|██████████| 30000/30000 [08:56<00:00, 55.96it/s]\n",
      "100%|██████████| 20000/20000 [05:57<00:00, 55.95it/s]\n",
      "100%|██████████| 10000/10000 [02:58<00:00, 55.90it/s]\n"
     ]
    }
   ],
   "source": [
    "adj_batch = ggclass.torch_batch_ii(X, btsz = batch_size, tol = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label, counts = np.unique(adj.cpu() == adj_batch.cpu(), return_counts = True)\n",
    "# print(label, counts / sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(adj_batch, 'data/H_gg_train_full.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavernn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
